<!DOCTYPE html>
<html lang="en">
  <head>
  
   
  <title>Olin College: SP2022 Social Technology Enterprise with Purpose (STEP)</title>
  
  <meta charset="utf-8" />
  <meta
    name="viewport"
    content="width=device-width, initial-scale=1.0, user-scalable=no"
  />
  
  
  <link rel="stylesheet" href="/css/main.css" />
    
  <noscript><link rel="stylesheet" href="/css/noscript.css" /></noscript>
  
  

<script>
    MathJax = {
        tex: {
            inlineMath: [['$', '$'], ['\\(', '\\)']],
            displayMath: [['$$', '$$'], ['\\[', '\\]']],
            processEscapes: true,
            processEnvironments: true
        },
        options: {
            skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        }
    };

    window.addEventListener('load', (event) => {
        document.querySelectorAll("mjx-container").forEach(function (x) {
            x.parentElement.classList += 'has-jax'
        })
    });

</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  
  <link
    rel="apple-touch-icon"
    sizes="180x180"
    href="/favicon_io/apple-touch-icon.png"
  />
  <link
    rel="icon"
    type="image/png"
    sizes="32x32"
    href="/favicon_io/favicon-32x32.png"
  />
  <link
    rel="icon"
    type="image/png"
    sizes="16x16"
    href="/favicon_io/favicon-16x16.png"
  />
  <link rel="manifest" href="/favicon_io/site.webmanifest" />
  
  <meta name="generator" content="Hugo 0.108.0"> <meta property="og:title" content="Olin College: SP2022 Social Technology Enterprise with Purpose (STEP)" />
<meta property="og:description" content="Gati Aher&#39;s personal page. Read reflections, notes, and guides for computer science and machine learning." />
<meta property="og:type" content="website" />
<meta property="og:url" content="http://GatiAher.github.io/tags/olin-college-sp2022-social-technology-enterprise-with-purpose-step/" /><meta property="og:image" content="http://GatiAher.github.io/img/cover_page.png"/>

</head>


  <body class="is-preload">
    
    
<div>
  <header id="header">
  <a href="/" class="title">Gati Aher</a>
  <nav>
    <ul>
      
      
      <li>
        <a href="http://GatiAher.github.io/categories/software-development/">Software Development (8)</a>
      </li>
      
      <li>
        <a href="http://GatiAher.github.io/categories/concepts-theory/">Concepts &amp; Theory (6)</a>
      </li>
      
      <li>
        <a href="http://GatiAher.github.io/categories/data-analysis/">Data Analysis (5)</a>
      </li>
      
      <li>
        <a href="/artwork">Art</a>
      </li>
    </ul>
  </nav>
</header>

  <div id="wrapper">
    
    <section id="list" class="wrapper">
      <header>
        <div class="center">
          <p><b>2 posts</b></p>
          
          
          <h1 class="tag-list-heading">Olin College: SP2022 Social Technology Enterprise with Purpose (STEP)</h1>
          
          
        </div>
      </header>
      <div class="inner">
        
        
        <div class="center">
          <h2>2022</h2>
        </div>
        <div class="posts">
           <article>
  <a href="/projects/imu-gesture-recognition/">
    <h1 class="major center">IMU Gesture Recognition</h1>
  </a>
  <p><p>This project analyzed and prepared a baseline machine learning model to perform gesture recognition on data collected with <a href="https://mbientlab.com/store/metamotionrl/">MbientLab MMRL IMU</a> rubber-banded to a two_finger ring. The final baseline model was trained with data from sessions 4, 5, and 7 consisting of 1,212 total instances of 4 gestures collected across 27 people.</p>
<p>When trained with a train-test split of 80:20, the model had an accuracy of 75%. The final model trained with full data (no train-test split) had reasonably robust performance in the real-time system (successfully generalized its gestures predictions to other people when integrated with the software demo app).</p>
<p>This report provides details on deciding on a gesture set, building and refining the gesture data collection process, and steps to integrate the model with the software iOS demo app.</p>
<div class="center">
  <ul class="actions">
       
    <li>
      <a href="https://github.com/OlinSTEP/signal-processing-gesture-data-collection" class="button icon outline brands fa-github">Visit GitHub</a>
    </li>
    
  </ul>
</div>



<div id="Container"
 style="padding-bottom:56.25%; position:relative; display:block; width: 100%">
 <iframe id="googleSlideIframe"
  width="100%" height="100%"
  src="https://docs.google.com/presentation/d/e/2PACX-1vT1MJqD9l2cEu7DgdtxDkJb_aH5ysP1NklfoNUuvb3sVjp9z3MezS0HFBOv-fLhV7ESwZks_xU1Z-wQ/embed?start=false&amp;loop=true&amp;delayms=3000"
  frameborder="0" allowfullscreen=""
  style="position:absolute; top:0; left: 0"></iframe>
</div></p>
  

  
  
  <ul class="actions">
    <li>
      <a
        href="/projects/imu-gesture-recognition/"
        class="button icon outline solid fa-arrow-right"
        >Read Report</a
      >
    </li>
  </ul>
  
</article>

          <hr />
           <article>
  <a href="/projects/reflecting-on-400-hours-of-data-collection-r-and-d/">
    <h1 class="major center">Reflecting on 400 Hours of Data Collection R&amp;D</h1>
  </a>
  <p><p>STEP (Social Technology Enterprise with Purpose) was an 400+ hour experimental course that aimed to give students real-world engineering experience within the freedoms afforded by an education-first structure. I worked on the gesture ring, designing a gesture set and building the data collection process for training a machine-learning gesture classification model.</p>
<p><strong>30-second demo video</strong>:

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/gtr_1zKshnQ" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="STEP Gesture Ring Demo"></iframe>
</div>
</p>
<p>This 20-page reflection includes criticisms and creative proposals that may be interesting to faculty developing iterations of STEP-like courses,  engineering students grappling with the process of designing a process, and my future self before I set on my next AR/VR, accessibility, machine-learning, or large integrated software development project.</p></p>
  

  
  
  <ul class="actions">
    <li>
      <a
        href="/projects/reflecting-on-400-hours-of-data-collection-r-and-d/"
        class="button icon outline solid fa-arrow-right"
        >Read Report</a
      >
    </li>
  </ul>
  
</article>

          <hr />
          
        </div>
        
      </div>
    </section>
  </div>

  
  <footer id="footer" class="wrapper style1-alt">
  <div class="inner">
    <ul class="menu">
      <li>&copy; 2022 <a href="/">Gati Aher</a></li>
      <li>Powered by <a href="https://gohugo.io/">Hugo</a></li>
      <li>
        Adapted 
        <a href="https://html5up.net/hyperspace"
          > from HTML5 UP</a
        >
      </li>
      <li>
        Code on <a href="https://github.com/GatiAher/gatiaher-hugo">GitHub</a>
      </li>
    </ul>
  </div>
</footer>

</div>



    
    

<script src="/js/jquery.min.js"></script>

<script src="/js/jquery.scrollex.min.js"></script>

<script src="/js/jquery.scrolly.min.js"></script>

<script src="/js/browser.min.js"></script>

<script src="/js/breakpoints.min.js"></script>

<script src="/js/util.js"></script>

<script src="/js/main.js"></script>


<script src="/js/tab_control.js"></script>


<script src="/js/carousel_control.js"></script>

  </body>
</html>
