<!DOCTYPE html>
<html lang="en">
  <head>
  
   
  <title>Data Analysis</title>
  
  <meta charset="utf-8" />
  <meta
    name="viewport"
    content="width=device-width, initial-scale=1.0, user-scalable=no"
  />
  
  
  <link rel="stylesheet" href="/css/main.css" />
    
  <noscript><link rel="stylesheet" href="/css/noscript.css" /></noscript>
  
  

<script>
    MathJax = {
        tex: {
            inlineMath: [['$', '$'], ['\\(', '\\)']],
            displayMath: [['$$', '$$'], ['\\[', '\\]']],
            processEscapes: true,
            processEnvironments: true
        },
        options: {
            skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        }
    };

    window.addEventListener('load', (event) => {
        document.querySelectorAll("mjx-container").forEach(function (x) {
            x.parentElement.classList += 'has-jax'
        })
    });

</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  
  <link
    rel="apple-touch-icon"
    sizes="180x180"
    href="/favicon_io/apple-touch-icon.png"
  />
  <link
    rel="icon"
    type="image/png"
    sizes="32x32"
    href="/favicon_io/favicon-32x32.png"
  />
  <link
    rel="icon"
    type="image/png"
    sizes="16x16"
    href="/favicon_io/favicon-16x16.png"
  />
  <link rel="manifest" href="/favicon_io/site.webmanifest" />
  
  <meta name="generator" content="Hugo 0.108.0"> <meta property="og:title" content="Data Analysis" />
<meta property="og:description" content="Gati Aher&#39;s personal page. Read reflections, notes, and guides for computer science and machine learning." />
<meta property="og:type" content="website" />
<meta property="og:url" content="http://GatiAher.github.io/categories/data-analysis/" /><meta property="og:image" content="http://GatiAher.github.io/img/cover_page.png"/>

</head>


  <body class="is-preload">
    
    
<div>
  <header id="header">
  <a href="/" class="title">Gati Aher</a>
  <nav>
    <ul>
      
      
      <li>
        <a href="http://GatiAher.github.io/categories/software-development/">Software Development (8)</a>
      </li>
      
      <li>
        <a href="http://GatiAher.github.io/categories/concepts-theory/">Concepts &amp; Theory (6)</a>
      </li>
      
      <li>
        <a href="http://GatiAher.github.io/categories/data-analysis/">Data Analysis (5)</a>
      </li>
      
      <li>
        <a href="/artwork">Art</a>
      </li>
    </ul>
  </nav>
</header>

  <div id="wrapper">
    
    <section id="list" class="wrapper">
      <header>
        <div class="center">
          <p><b>5 posts</b></p>
          
          
          <h1 class="category-list-heading">Data Analysis</h1>
          
          
        </div>
      </header>
      <div class="inner">
        
        
        <div class="center">
          <h2>2022</h2>
        </div>
        <div class="posts">
           <article>
  <a href="/projects/imu-gesture-recognition/">
    <h1 class="major center">IMU Gesture Recognition</h1>
  </a>
  <p><p>This project analyzed and prepared a baseline machine learning model to perform gesture recognition on data collected with <a href="https://mbientlab.com/store/metamotionrl/">MbientLab MMRL IMU</a> rubber-banded to a two_finger ring. The final baseline model was trained with data from sessions 4, 5, and 7 consisting of 1,212 total instances of 4 gestures collected across 27 people.</p>
<p>When trained with a train-test split of 80:20, the model had an accuracy of 75%. The final model trained with full data (no train-test split) had reasonably robust performance in the real-time system (successfully generalized its gestures predictions to other people when integrated with the software demo app).</p>
<p>This report provides details on deciding on a gesture set, building and refining the gesture data collection process, and steps to integrate the model with the software iOS demo app.</p>
<div class="center">
  <ul class="actions">
       
    <li>
      <a href="https://github.com/OlinSTEP/signal-processing-gesture-data-collection" class="button icon outline brands fa-github">Visit GitHub</a>
    </li>
    
  </ul>
</div>



<div id="Container"
 style="padding-bottom:56.25%; position:relative; display:block; width: 100%">
 <iframe id="googleSlideIframe"
  width="100%" height="100%"
  src="https://docs.google.com/presentation/d/e/2PACX-1vT1MJqD9l2cEu7DgdtxDkJb_aH5ysP1NklfoNUuvb3sVjp9z3MezS0HFBOv-fLhV7ESwZks_xU1Z-wQ/embed?start=false&amp;loop=true&amp;delayms=3000"
  frameborder="0" allowfullscreen=""
  style="position:absolute; top:0; left: 0"></iframe>
</div></p>
  

  
  
  <ul class="actions">
    <li>
      <a
        href="/projects/imu-gesture-recognition/"
        class="button icon outline solid fa-arrow-right"
        >Read Report</a
      >
    </li>
  </ul>
  
</article>

          <hr />
          
        </div>
        
        <div class="center">
          <h2>2021</h2>
        </div>
        <div class="posts">
           <article>
  <a href="/projects/handwriting-detection-with-faster-r-cnn-plus-experiments/">
    <h1 class="major center">Handwriting Detection With Faster R-CNN &#43; Experiments</h1>
  </a>
  <p><p><a href="https://indico.io/">Indico Data Solutions</a> provides services to extract information from scanned pdfs. Since their existing OCR + NLP pipeline did not extract handwriting, one of my internship projects involved creating a robust solution to detect and classify handwriting using a deep learning computer vision model.</p>
<p>I started by fine-tuning upon the <a href="https://arxiv.org/abs/1506.01497">Faster R-CNN model</a> from the <a href="https://github.com/facebookresearch/detectron2">Detectron-v2 framework</a>. Then I tried to improve upon the baseline performance with (i) different pre-training tasks, (ii) multi-label formulation, (iii) strategies to improve small object detection, and (iv) different label sets and datasets. This report documents my methods and finishes with a class confusion analysis and retrospective.</p></p>
  
<span class="image fit">
  <img src="http://GatiAher.github.io/projects/handwriting-detection-with-faster-r-cnn-plus-experiments/cover.png" />
</span>


  
  
  <ul class="actions">
    <li>
      <a
        href="/projects/handwriting-detection-with-faster-r-cnn-plus-experiments/"
        class="button icon outline solid fa-arrow-right"
        >Read Report</a
      >
    </li>
  </ul>
  
</article>

          <hr />
           <article>
  <a href="/projects/emg-gesture-recognition.md/">
    <h1 class="major center">EMG Gesture Recognition</h1>
  </a>
  <p><p>This project followed the topological data analysis steps laid out in <a href="http://doi.org/10.1098/rsif.2017.0734">Phinyomark et al (2017) &ldquo;Navigating features: a topologically informed chart of electromyographic features space&rdquo;</a> to analyze 43 features extracted from surface EMG signals of three gestures (rock, paper, scissors) performed by a single subject.</p>
<p>I used sklearn&rsquo;s topological data analysis tools with the Kepler Mapper and Ward&rsquo;s minimum variance method as the criterion for hierarchial clustering in order to analyze feature redundancy. Comparison of feature class separability was analyzed by calculating Davies-Bouldin index (DBI) and Fisher&rsquo;s linear discriminant index (FLDI), and measuring misclassification rates. 5-fold cross validation Linear Discriminant Analysis and Support Vector Machine were employed as classifiers.</p>
<div class="center">
  <ul class="actions">
       
    <li>
      <a href="https://github.com/GatiAher/EMG_Gesture_Recognition" class="button icon outline brands fa-github">Visit GitHub</a>
    </li>
    
  </ul>
</div></p>
  
<span class="image fit">
  <img src="http://GatiAher.github.io/projects/emg-gesture-recognition.md/cover.png" />
</span>


  
  
</article>

          <hr />
           <article>
  <a href="/projects/facial-recognition-using-principal-component-analysis/">
    <h1 class="major center">Facial Recognition Using Principal Component Analysis</h1>
  </a>
  <p><p>I have used multiple variations of Principal Component Analysis (PCA) in my research on microbial community analysis. To explain the core theory and assumptions of PCA to my lab group, I fleshed out an analysis of a toy example (eigenfaces) that I had originally seen in class. This analysis reasons about the assumptions of PCA and the effects of applying it to out-of-distribution data by using PCA to perform facial recognition on a dataset of my classmates&rsquo; faces.</p>
<p><em>I was invited to present this project at <a href="https://ms-my.facebook.com/MathUpConference/photos/because-the-mathup-conference-is-conducted-in-both-polish-and-english-another-du/2805409529774282">Łódź University&rsquo;s SP2021 [virtual] MathUp conference</a> at Łódź University, Poland. The conference was an incredibly fun opportunity to meet fellow researchers and data scientists!</em></p></p>
  
<span class="image fit">
  <img src="http://GatiAher.github.io/projects/facial-recognition-using-principal-component-analysis/2D_visualization.png" />
</span>


  
  
  <ul class="actions">
    <li>
      <a
        href="/projects/facial-recognition-using-principal-component-analysis/"
        class="button icon outline solid fa-arrow-right"
        >Read Report</a
      >
    </li>
  </ul>
  
</article>

          <hr />
           <article>
  <a href="/projects/a-fourier-transform-detective-story/">
    <h1 class="major center">A Fourier Transform Detective Story!</h1>
  </a>
  <p><p>A group of research students had tried to use a 2D discrete Fourier Transform to characterize the pattern of repeating protein units on a bacteria surface layer image. Since their spectral graph looked unusually messy and their pattern estimates seemed very wrong, my research professor asked me to take a crack at interpreting and cleaning it. This was a neat application of understanding the mathematical assumptions of a technique to properly isolate and interpret results.</p></p>
  
<span class="image fit">
  <img src="http://GatiAher.github.io/projects/a-fourier-transform-detective-story/cover.png" />
</span>


  
  
  <ul class="actions">
    <li>
      <a
        href="/projects/a-fourier-transform-detective-story/"
        class="button icon outline solid fa-arrow-right"
        >Read Report</a
      >
    </li>
  </ul>
  
</article>

          <hr />
          
        </div>
        
      </div>
    </section>
  </div>

  
  <footer id="footer" class="wrapper style1-alt">
  <div class="inner">
    <ul class="menu">
      <li>&copy; 2022 <a href="/">Gati Aher</a></li>
      <li>Powered by <a href="https://gohugo.io/">Hugo</a></li>
      <li>
        Adapted 
        <a href="https://html5up.net/hyperspace"
          > from HTML5 UP</a
        >
      </li>
      <li>
        Code on <a href="https://github.com/GatiAher/gatiaher-hugo">GitHub</a>
      </li>
    </ul>
  </div>
</footer>

</div>



    
    

<script src="/js/jquery.min.js"></script>

<script src="/js/jquery.scrollex.min.js"></script>

<script src="/js/jquery.scrolly.min.js"></script>

<script src="/js/browser.min.js"></script>

<script src="/js/breakpoints.min.js"></script>

<script src="/js/util.js"></script>

<script src="/js/main.js"></script>


<script src="/js/tab_control.js"></script>


<script src="/js/carousel_control.js"></script>

  </body>
</html>
