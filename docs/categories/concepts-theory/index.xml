<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Concepts &amp; Theory on Gati Aher&#39;s Blog</title>
    <link>http://GatiAher.github.io/categories/concepts-theory/</link>
    <description>Recent content in Concepts &amp; Theory on Gati Aher&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 20 May 2022 12:21:08 -0400</lastBuildDate><atom:link href="http://GatiAher.github.io/categories/concepts-theory/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Intuition for Linear Programming</title>
      <link>http://GatiAher.github.io/projects/intuition-for-linear-programming/</link>
      <pubDate>Fri, 20 May 2022 12:21:08 -0400</pubDate>
      
      <guid>http://GatiAher.github.io/projects/intuition-for-linear-programming/</guid>
      <description>&lt;p&gt;Understanding the geometric intuition and algorithms for solving linear programming problems. Covers (1) defining the solution space as the area within a convex polytope space, (2) understanding that the optimal solution occurs at a vertex point and translating that geometric intuition and more efficient search path into the Simplex matrix-based algorithm, (3) the idea of Duality and how it exposes additional information, and (4) how the Interior Point method works not just for linear programs, but also for more general convex optimization problems.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Exploring FPGA Deep Learning Accelerators</title>
      <link>http://GatiAher.github.io/projects/exploring-fpga-deep-learning-accelerators/</link>
      <pubDate>Thu, 23 Dec 2021 20:08:21 -0500</pubDate>
      
      <guid>http://GatiAher.github.io/projects/exploring-fpga-deep-learning-accelerators/</guid>
      <description>&lt;p&gt;I wanted to learn about the process of using FPGA hardware accelerators for more power-efficient deep learning inference. Through this project, I learned about the process of creating and building an image for the Zybo ZYNQ FPGA, PYNQ application development, and Vitis AI development tools. I also surveyed the functionality of FINN, an experimental framework from Xilinx Research Labs to explore quantized deep neural network inference on FPGAs.&lt;/p&gt;
&lt;div id=&#34;Container&#34;
  style=&#34;padding-bottom:56.25%; position:relative; display:block; width: 100%&#34;&gt;
  &lt;iframe id=&#34;googlePdfIframe&#34;
  width=&#34;100%&#34; height=&#34;100%&#34;
  src=&#34;https://drive.google.com/file/d/1SVpb3sdzzIIEaEiwaT3kFwRgV2HywIRb/preview&#34;
  frameborder=&#34;0&#34; allowfullscreen=&#34;&#34;
  style=&#34;position:absolute; top:0; left: 0&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Procedural Graph Generation For More Realistic Simulations</title>
      <link>http://GatiAher.github.io/projects/procedural-graph-generation-for-more-realistic-simulations/</link>
      <pubDate>Sat, 18 Dec 2021 23:23:16 -0500</pubDate>
      
      <guid>http://GatiAher.github.io/projects/procedural-graph-generation-for-more-realistic-simulations/</guid>
      <description>&lt;p&gt;Many real world systems can be modeled with graphs. Most stable and complex graphs have &lt;strong&gt;small-world&lt;/strong&gt; (local clustering) and &lt;strong&gt;scale-free&lt;/strong&gt; (hubs) properties. In this project, we (1) identified algorithms that generated small-world and scale-free graphs, (2) studied and implemented generation functions for each type of algorithm, (3) created custom animations of graph generation process, and (4) verified that our graphs exhibited the expected structural properties.&lt;/p&gt;
&lt;ul class=&#34;actions&#34;&gt;
    
    
    
        
        &lt;li&gt;&lt;a href=&#34;https://github.com/GatiAher/network-generation&#34; class=&#34;button icon solid brands fa-github&#34;&gt;Visit GitHub&lt;/a&gt;&lt;/li&gt;
    
&lt;/ul&gt;


&lt;div id=&#34;Container&#34;
 style=&#34;padding-bottom:56.25%; position:relative; display:block; width: 100%&#34;&gt;
 &lt;iframe id=&#34;googleSlideIframe&#34;
  width=&#34;100%&#34; height=&#34;100%&#34;
  src=&#34;https://docs.google.com/presentation/d/e/2PACX-1vRoVNJKtW84R-zlSBe9CBJO1PGcZwgc7_wVDoCUYklCmjqXsDLeqK1ipSAd0XweKgvaql3kSxRcF7YA/embed?start=false&amp;amp;loop=false&amp;amp;delayms=3000&#34;
  frameborder=&#34;0&#34; allowfullscreen=&#34;&#34;
  style=&#34;position:absolute; top:0; left: 0&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Deep Dive Into Huffman Coding</title>
      <link>http://GatiAher.github.io/projects/deep-dive-into-huffman-coding/</link>
      <pubDate>Mon, 25 Oct 2021 00:46:56 -0500</pubDate>
      
      <guid>http://GatiAher.github.io/projects/deep-dive-into-huffman-coding/</guid>
      <description>&lt;p&gt;Huffman coding is a variation on prefix codes that optimize lossless data compression. In this deep dive, we (1) introduced how Huffman Codes work, (2) explored the theoretical limits of Huffman compression, (3) analyzed resilience to error, and (4) followed the evolution of research on using choice of Huffman tables to encode secret messages in MP3 files.&lt;/p&gt;
&lt;div id=&#34;Container&#34;
  style=&#34;padding-bottom:56.25%; position:relative; display:block; width: 100%&#34;&gt;
  &lt;iframe id=&#34;googlePdfIframe&#34;
  width=&#34;100%&#34; height=&#34;100%&#34;
  src=&#34;https://drive.google.com/file/d/1qZT_iiq8OeSeb5d5wkv4Jp9Ie-83-cm0/preview&#34;
  frameborder=&#34;0&#34; allowfullscreen=&#34;&#34;
  style=&#34;position:absolute; top:0; left: 0&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Survey of Data Structures for Large Scale Information Retrieval</title>
      <link>http://GatiAher.github.io/projects/survey-of-data-structures-for-large-scale-information-retrieval/</link>
      <pubDate>Sun, 09 May 2021 21:21:42 -0400</pubDate>
      
      <guid>http://GatiAher.github.io/projects/survey-of-data-structures-for-large-scale-information-retrieval/</guid>
      <description>&lt;p&gt;A survey of data structures used in large-scale information systems. Covers (i) how the inverted index data structure allows for constant time querying (ii) the need, problems, and clever design details of methods to compress big numbers (focusing on Elias-Fano and Partitioned Elias-Fano), and (iii) BitFunnel, an unusual probabilistic data structure used by the Bing search engine to bypass the curse of inverted index global updates.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5-minute video summary&lt;/strong&gt;:

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/UN6_yzZyczE&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;Understanding Large Data Retrieval Systems: Data Structures and Optimizations&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>1D and 2D Fourier Transforms</title>
      <link>http://GatiAher.github.io/projects/1d-and-2d-fourier-transforms/</link>
      <pubDate>Wed, 03 Mar 2021 14:22:03 -0400</pubDate>
      
      <guid>http://GatiAher.github.io/projects/1d-and-2d-fourier-transforms/</guid>
      <description>&lt;p&gt;Concepts and math behind 1D and 2D discrete Fourier Transforms for signal and image analysis. Overview of mathematical steps, post-processing, assumptions, and reading of phase and magnitude plots.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
